

```markdown
# QuickStart Guide: Building Your Research Dataset from Scratch

âš¡ **The Two-Step AI Library â€“ actually a reliable three-stage pipeline**

This repository gives you an automated, resume-aware, audit-driven, cost-efficient system to convert raw book images into structured, research-ready JSON datasets.

## ğŸŸ¢ 1. Environment & API Setup

Before running anything, set up your environment and credentials.

### Activate Virtual Environment

```bash
# Navigate to project root
cd /path/to/your/folder

# Create and activate
python3 -m venv .venv
source .venv/bin/activate

# Install core dependencies
pip install openai pillow
```

### Persistent API Keys

Add your key so it survives new terminal sessions:

```bash
echo 'export OPENAI_API_KEY="your_actual_key"' >> ~/.zshrc
source ~/.zshrc
```

**VS Code Tip**: If VS Code keeps using system Python or a "ghost" env:

```bash
rm -rf .venv
```

Then re-open the folder â€” it should prompt to use the new `.venv`.

## ğŸ›  2. The Three-Stage Pipeline

### Stage 1: High-Fidelity Extraction (Ingestion)
Converts raw images â†’ structured JSON objects.

```bash
python stage1_ingestion.py
```

- **Resume-aware**: Skips images that already have a matching JSON
- **Data Prep**: Organize images in folders like:  
  `BookTitle_AuthorName/01_page.jpg`, `BookTitle_AuthorName/02_page.jpg`, etc.

### Stage 2: Operations Center (Audit)
Cross-checks images vs. processed library â†’ finds sequence gaps.

```bash
python stage2_audit.py
```

- **Output**: `gap_analysis_report.json`  
  Shows completion % per book + exact missing page numbers

### Stage 3: Precision Infill (Refinement)
Targets incomplete books and processes **only** missing pages.

```bash
python stage3_gap_filler.py
```

- Interactive CLI: Choose which book(s) to complete  
- Prevents wasting API calls on already-finished content

## ğŸ” 3. Quality Control & Synthesis

After ingestion:

- **Thematic Filtering** â€” Combine results into filtered master tables (e.g., body sensations only)  
- **Accuracy Audit**  
  ```bash
  python stage4_accuracy_audit.py
  ```
  â†’ Generates Trust Scores + verifies transcription fidelity

## âœ… Success Checklist

- No duplicate pages in final output (global deduplication)
- `which python` points to `.venv/bin/python` (not system Python)
- All books in `gap_analysis_report.json` show **100.0%** completion

You're done when: structured dataset + high trust scores + zero gaps.

Good luck with your research! ğŸš€

```
